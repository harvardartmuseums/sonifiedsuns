# Sonified Suns

This project, based on Jeff Steward's Suns Explorer, represents randomly chosen objects from the Harvard Art Museums' collections in sound. Using color data from the Harvard Art Museums' API, the project displays the "suns" of color&mdash;concentric circles scaled in proportion to their significance in the work&mdash;that Jeff's project centers around, while simultaneously producing an auditory equivalent. A voice reads basic dogtag information on the current work before tones sound, their pitch mapped to hue, their volume to saturation, their echo to work size, and their timing to percentage of the work. Speech interaction allows visitors to comment, hear an explanation, or hear others' comments.

### To run this project, open http://sonifiedsuns.herokuapp.com/screens.html on one device and http://sonifiedsuns.herokuapp.com/shades.html on another within about 30 seconds of each other. 

### Both parts use features unique to Google Chrome. 

### To use speech interaction, the device running http://sonifiedsuns.herokuapp.com/shades.html must have a microphone attached.
